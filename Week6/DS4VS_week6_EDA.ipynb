{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SmilodonCub/DS4VS/blob/master/Week6/DS4VS_week6_EDA.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "# Week 6: EDA\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### a Brief Recap:\n",
    "\n",
    "* Hello, how are you?\n",
    "* Some changes to the Syllabus: PsychoPy class will become a second day for Visualization\n",
    "* Today:\n",
    "    * look over some code to import example 'real world' data files\n",
    "    * an example of using a function to iterate over data files\n",
    "    * In the next notebook: data missingness & data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EDA\n",
    "\n",
    "Today we're all about **Exploratory Data Analysis**  \n",
    "\n",
    "We'll start by looking at **data wrangling** - ways to import and give structure to our data files\n",
    "\n",
    "\n",
    "### Environmental Dependancies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example Files\n",
    "\n",
    "* EEG.txt\n",
    "* ERG.txt\n",
    "* pupil.txt\n",
    "* a .mat mystery\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### EEG.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_url = 'https://raw.githubusercontent.com/SmilodonCub/DS4VS/master/Week6/EEG.txt'\n",
    "#EEG_df = pd.read_csv( EEG_url )\n",
    "#EEG_df = pd.read_csv( EEG_url, encoding= 'unicode_escape' )\n",
    "#EEG_df = pd.read_csv( EEG_url, sep = '\\t', encoding= 'unicode_escape' )\n",
    "EEG_df = pd.read_csv( EEG_url, skiprows = range( 0, 38 ), sep = '\\t', encoding= 'unicode_escape'  )\n",
    "EEG_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "EEG_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Further formatting necessary\n",
    "\n",
    "`usecols` to specify which '\\t' delineated columns from the .txt file to access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_df = pd.read_csv( EEG_url, skiprows = range( 0, 38 ), sep = '\\t', usecols = range( 6, 69 ) )\n",
    "EEG_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "EEG_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Quick & dirty visualization\n",
    "\n",
    "Just take a quick peak at one of the channels...  \n",
    "...Is this what we expect to see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_df.plot(  x = 'Time (ms)', y = 'Trial (nV).10' ) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ERG.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ERG_url = 'https://raw.githubusercontent.com/SmilodonCub/DS4VS/master/Week6/ERG.txt'\n",
    "ERG_df = pd.read_csv( ERG_url, sep = '\\t', \n",
    "                     usecols = range( 44, 77 ), \n",
    "                     encoding= 'unicode_escape',\n",
    "                     header = None)\n",
    "print( ERG_df.columns )\n",
    "ERG_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "chan_names = [ 'chan_{}'.format( x ) for x in range( 0, 33 ) ]\n",
    "ERG_df.columns = chan_names\n",
    "ERG_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print( ERG_df.shape )\n",
    "ERG_df.plot( x = 'chan_0', y = 'chan_1' ) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### A Pattern Emerges...\n",
    "\n",
    "Glancing at the data we can see a pattern in the columns: time, dataX, dataY  \n",
    "I'm giving the data columns two arbitrary names here; we'll need info from our domain expert.  \n",
    "\n",
    "Let's rename the columns..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "colnames = [ ['time_{}'.format(x), 'chan_X_{}'.format(x), 'chan_Y_{}'.format(x)] for x in range( 0, int( ERG_df.shape[1] /3 ) ) ]\n",
    "colnames = [item for sublist in colnames for item in sublist]\n",
    "colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the column names\n",
    "ERG_df.columns = colnames\n",
    "ERG_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Alternatively, we could check to see if the columns are identical. if so, drop the duplicates.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERG_df['time_0'].equals( ERG_df['time_1'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### A Quick and dirty visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(5, 7))\n",
    "for idx in range(1,12):\n",
    "    time_str = 'time_{}'.format(idx-1)\n",
    "    X_str = 'chan_X_{}'.format(idx-1)\n",
    "    Y_str = 'chan_Y_{}'.format(idx-1)\n",
    "    plt.subplot(11,1,idx)\n",
    "    sns.lineplot( data = ERG_df, x= time_str, y= X_str )\n",
    "    plt.ylim( -50000, 100000 )\n",
    "    \n",
    "sns.despine(left=True, bottom=True, right=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### pupil.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_url = 'https://raw.githubusercontent.com/SmilodonCub/DS4VS/master/Week6/pupil.txt'\n",
    "pupil_df = pd.read_csv( pupil_url, sep = '\\t' )\n",
    "pupil_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pupil_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print( pupil_df.shape )\n",
    "pupil_df.info()\n",
    "pupil_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### A Quick & dirty visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(5, 5))\n",
    "plt.subplot(2,1,1)\n",
    "sns.lineplot( data = pupil_df, x= 'time', y= 'pupilArea' )\n",
    "plt.subplot(2,1,2)\n",
    "sns.lineplot( data = pupil_df, x= 'time', y= 'pupilDiam' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MATLAB struct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/bonzilla/Documents/ScienceLife/DS4VS/Week6/sampledata.mat'\n",
    "\n",
    "mat_dat = scipy.io.loadmat(path)\n",
    "print( type( mat_dat ) )\n",
    "print( mat_dat.keys() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's start by investigating the keys..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print( mat_dat['__header__'] )\n",
    "print( mat_dat['__version__'] )\n",
    "print( mat_dat['__globals__'] )\n",
    "EEGmat = mat_dat['sampledata']\n",
    "EEGmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "EEGmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It looks like the dunders are all file metadata. Not relevant? (let's ask our expert)  \n",
    "We are mainly concerned with formatting the data in `sampledata`  \n",
    "\n",
    "`mat_dat['sampledata']` is a deeply nested structure... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_dat['sampledata'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampledata.channels\n",
    "channels = mat_dat['sampledata'][0][0][0][0]\n",
    "channel_list = [ chan_num[0][0] for chan_num in channels ]\n",
    "channel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampledata.fielname\n",
    "filename = mat_dat['sampledata'][0][0][1][0]\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampledata.maps\n",
    "mat_dat['sampledata'][0][0][2][0,2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# sampledata.psth_range\n",
    "psth_range = mat_dat['sampledata'][0][0][3]\n",
    "print( psth_range.shape )\n",
    "print( type( psth_range ) )\n",
    "psth_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot( psth_range[0] ) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampledata.n_channels\n",
    "n_channels = mat_dat['sampledata'][0][0][4][0][0]\n",
    "n_channels\n",
    "# QUESTION FOR FARZANEH: why is n_channel 20, but the 'channel' field only lists 16?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Wrangling\n",
    "\n",
    "<img src=\"data_preprocessing.jpg\" width=\"30%\" style=\"margin-left:auto; margin-right:auto\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example Data Import\n",
    "\n",
    "1. create code to import the data in a managable format\n",
    "2. functionalize import code\n",
    "3. apply function the multiple files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. Create code to import/format data\n",
    "\n",
    "We just saw several example of this above, here's one more!  \n",
    "The following code will bring in select values from a .txt file.  \n",
    "This .txt file is one of many for a psychophysical experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addy = '/home/bonzilla/Documents/ScienceLife/DS4VS/datasets/gratvernier/mj gratvernier 49.txt'\n",
    "lines = []\n",
    "fp = open(addy)\n",
    "for line in fp:\n",
    "    lines.append( line )\n",
    "    print( line )\n",
    "\n",
    "fp.close()\n",
    "#print( lines )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### what to do with a list of lines?\n",
    "\n",
    "We now need to write code to pull out information based on known patterns in the .txt file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of our list of lines\n",
    "print( len( lines ) )\n",
    "print( lines[0:32] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### information dictionary\n",
    "\n",
    "* subject and stimulus information is given in the extensive header of this file.  \n",
    "* lines 1 to ~32 are the same across all files, so we can use that to our advantange to pull the information we need  \n",
    "* We will store fields of interest in a Python dictionary..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# initialize a python dictionary\n",
    "verniergrat_dict = {}\n",
    "\n",
    "# add a few fields\n",
    "verniergrat_dict['date'] = lines[2].split()[0]\n",
    "verniergrat_dict['subject'] = lines[3][0:2]\n",
    "verniergrat_dict['spac_freq'] = lines[5].split()[3]\n",
    "verniergrat_dict['drift vel'] = lines[6].split()[2] \n",
    "verniergrat_dict['grat_gap'] = lines[7].split()[4]\n",
    "verniergrat_dict['eccentricity'] = lines[5].split()[3]\n",
    "verniergrat_dict['spac_freq'] = lines[5].split()[3]\n",
    "\n",
    "print( verniergrat_dict )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2. Functionalize the import/format code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The dictionary doesn't hold all the information we'd need for analysis, but it's a good start.  \n",
    "Let's functionalize the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gratvernier_txt2dict( path, filename ):\n",
    "    \"\"\"\n",
    "    helper function to extract data and task metadata from a BBL .txt file\n",
    "    \"\"\"\n",
    "    # read lines into python environment\n",
    "    file_add = path + filename\n",
    "    lines = []\n",
    "    fp = open(file_add)\n",
    "    for line in fp:\n",
    "        lines.append( line )\n",
    "    fp.close()\n",
    "    \n",
    "    # pull info of interest and store as a python dictionary\n",
    "    verniergrat_dict = {}\n",
    "    \n",
    "    verniergrat_dict['filename'] = filename\n",
    "    verniergrat_dict['date'] = lines[2].split()[0]\n",
    "    verniergrat_dict['subject'] = lines[3][0:2]\n",
    "    verniergrat_dict['spac_freq'] = lines[5].split()[3]\n",
    "    verniergrat_dict['drift vel'] = lines[6].split()[2]\n",
    "    verniergrat_dict['grat_gap'] = lines[7].split()[4]\n",
    "    verniergrat_dict['eccentricity'] = lines[5].split()[3]\n",
    "    verniergrat_dict['spac_freq'] = lines[5].split()[3]\n",
    "    \n",
    "    # return the data dictionary\n",
    "    return verniergrat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### take this function for a test drive: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/bonzilla/Documents/ScienceLife/DS4VS/datasets/gratvernier/'\n",
    "filename = 'mj gratvernier 49.txt'\n",
    "\n",
    "exp1 = gratvernier_txt2dict( path, filename )\n",
    "print( exp1 )\n",
    "print( type( exp1 ) )\n",
    "print( exp1.keys() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now you try.....\n",
    "\n",
    "* functionalize some of the code from a previous example\n",
    "* write a function that will read a file and return some structured data\n",
    "\n",
    "a basic outline:  \n",
    "\n",
    "    def basic_dataread( str_path ):\n",
    "        \"\"\"\n",
    "        write a blurb to describe what this function will do\n",
    "        \"\"\"\n",
    "        path = \".......\" # provide the path where your file lives\n",
    "        \n",
    "        # use the appropriate function to read the file\n",
    "        \n",
    "        # write code to format/select data of interest\n",
    "        \n",
    "        return <data_object>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### iterating over many files\n",
    "\n",
    "We would like to use our function to iterate over many files and extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many files are in the folder? \n",
    "folder = '/home/bonzilla/Documents/ScienceLife/DS4VS/datasets/gratvernier/'\n",
    "\n",
    "import os\n",
    "files = os.listdir( folder ) \n",
    "print( len( files ) )\n",
    "print( files )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### iterating over many files\n",
    "\n",
    "There are 59 .txt files in the same directory as our working example.  \n",
    "It wouldn't be impossible to manually work through them with cut/paste, but our time is more valuable than that!!!  \n",
    "\n",
    "Let's have Python do the work for us..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files: \n",
    "    file_path = '/home/bonzilla/Documents/ScienceLife/DS4VS/datasets/gratvernier/'\n",
    "    res = gratvernier_txt2dict( file_path, file )\n",
    "    print( file )\n",
    "    print( res )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. Iterate over multiple data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Consolidate the outcomes as a pandas DataFrame\n",
    "\n",
    "printing the results is not very useful to us.  \n",
    "Let's write another function that will consolidate the outcomes from `gratvernier_txt2dict()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def gratvernier_text2df( path, extension ):\n",
    "    \"\"\"\n",
    "    given a folder 'path' (str) and file 'extension' (str),\n",
    "    gratvernier_txt2df() returns a pandas DataFrame that consolidates\n",
    "    the dict fields from gratvernier_txt2dict()\n",
    "    \"\"\"\n",
    "    # a list of data files to iterate over\n",
    "    files = os.listdir( folder )\n",
    "    files = [file for file in files if extension in file]\n",
    "    data_fields = ['date', 'subject', \n",
    "                   'spac_freq', 'drift vel', \n",
    "                   'grat_gap', 'eccentricity']\n",
    "    dict_list = []\n",
    "    for file in files:\n",
    "        row = gratvernier_txt2dict( path, file )\n",
    "        dict_list.append( row )\n",
    "        \n",
    "    data_df = pd.DataFrame( dict_list )\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Let's take this function out for a test drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "folder = '/home/bonzilla/Documents/ScienceLife/DS4VS/datasets/gratvernier/'\n",
    "\n",
    "res = gratvernier_text2df( folder, '.txt' )\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Are we happy with this result?\n",
    "\n",
    "Let's get a better view of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dtype `object`\n",
    "\n",
    "Take a moment and look at the DataFrame further...  \n",
    "\n",
    "\n",
    "<img src=\"https://internationalnewsagency.org/wp-content/uploads/2020/11/face-with-a-raised-eyebrow-emoji-780x470.jpg\" width=\"60%\" style=\"margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's take a break. When we come back we will talk about cleaning and evaluating data\n",
    "<img src=\"https://content.techgig.com/photo/80071467/pros-and-cons-of-python-programming-language-that-every-learner-must-know.jpg?132269\" width=\"100%\" style=\"margin-left:auto; margin-right:auto\">"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
